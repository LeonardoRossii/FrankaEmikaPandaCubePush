GOAL:
You are a Reinforcement Learning and Robotics Engineer. Given a the function '_setup_observables' defining the list of observables and the function
'evaluate' where the robot rollout is computed, your goal is to define a list of  numeric metrics, based on a subset of the observables, to describe the trajectory of the robot during his task and 
update the 'evaluate' function in order that it returns a dictionary containing the evolution during the episode of the metrics. Thes metrics will be fundamental to evaluate how good the trajectory is.

TASK:
The robot gripper is close to a cube, first it must reach the cube and and then with the gripper fingers touch it and push it to the goal position avoiding to touch the table and avoiding the occurrence of the Irreversible Events.

YOUR OUTPUT:
Return the same exact agent.py script but with the evaluate function changed.

EXAMPLE:
    def evaluate(self, weights, max_n_timesteps):
        self.safe_filter.reset()
        obs = self.env.reset()
        state = self.get_state(obs)
        self.set_weights(weights)
        
        slip = 0
        
        rollout_cube_to_goal_dist = []
        rollout_slip = []
        params = [0]

        for t in range(max_n_timesteps):

            state = self.get_state(obs)
            action = self.forward(state)  
            reactive_action,_,_ = self.safe_filter.apply(action)

            if t%10 == 0:
                rollout_cube_to_goal_dist.append(np.linalg.norm(obs["cube_to_goal"]))
                rollout_slip.append(bool(obs["cube_slip"]))

        obs, _, done, _, = self.env.step(action, params)
        
        if done or self.env.check_success() or self.env.check_failure():
            metrics = {"rollout_cube_to_goal_dist": rollout_cube_to_goal_dist,
                        "rollout_accomplished":  bool(self.env.check_success())
                    }
            break        

        return metrics
